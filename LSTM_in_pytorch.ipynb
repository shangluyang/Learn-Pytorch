{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Pytorch's LSTM expects all of its inputs to be 3D tensors\n",
        "\n",
        "1. The first axis is the sequence itself\n",
        "2. The second indexes instances in the mini-batch\n",
        "3. The third indexes elements of the input"
      ],
      "metadata": {
        "id": "ZKe3oIt6OmcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Author: Robert Guthrie\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuM6M1OhO8QP",
        "outputId": "b5569e5d-d0d6-4ef3-8d22-71bbaa5fca83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa17c4cb510>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14hqI3AyinQE",
        "outputId": "01e378d6-4211-4aea-f346-c6b7f4f1de55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### example"
      ],
      "metadata": {
        "id": "De4wEsJuRn7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = nn.LSTM(3, 3)\n",
        "inputs = [torch.randn(1, 3) for _ in range(5)]\n",
        "# h_0, c_o\n",
        "hidden = (torch.randn(1, 1, 3),\n",
        "          torch.randn(1, 1, 3))\n",
        "\n",
        "for item in inputs:\n",
        "  out, hidden = lstm(item.view(1, 1, -1), hidden)"
      ],
      "metadata": {
        "id": "ChQvCmJqRaLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### concat entire sequence at once"
      ],
      "metadata": {
        "id": "hWp3J-x7TXiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [torch.randn(1, 3) for _ in range(5)]\n",
        "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
        "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
        "out, hidden = lstm(inputs, hidden)"
      ],
      "metadata": {
        "id": "tPxQDcOiSUvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_KFPi1TfcM",
        "outputId": "2fd0121a-4d2c-4781-fae1-bd2f66a38f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6383, -0.1405, -0.1033]],\n",
              "\n",
              "        [[-0.1460, -0.0367, -0.2437]],\n",
              "\n",
              "        [[-0.4672, -0.0584, -0.2693]],\n",
              "\n",
              "        [[-0.5145,  0.0216, -0.2656]],\n",
              "\n",
              "        [[-0.1504,  0.0266, -0.1379]]], grad_fn=<MkldnnRnnLayerBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: An LSTM for Part-of-Speech Tagging\n",
        "\n",
        "Let $w_1, \\cdots w_M$ be input sentence, where $w_i \\in V$. Let T be our tag set, and $y_i$ be the tag of word $w_i$."
      ],
      "metadata": {
        "id": "Zt1eUAkwUqkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "  idxs = [to_ix[w] for w in seq]\n",
        "  return torch.tensor(idxs, dtype = torch.long).cuda() "
      ],
      "metadata": {
        "id": "um9xSSShUjo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = [\n",
        "    # Tags are: DET - determiner; NN - noun; V - verb\n",
        "    # For example, the word \"The\" is a determiner\n",
        "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
        "]\n",
        "\n",
        "word_to_ix = {}\n",
        "for sentence, tags in training_data:\n",
        "  for word in sentence:\n",
        "    if word not in word_to_ix:\n",
        "      # assign each word with unique index\n",
        "      word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6"
      ],
      "metadata": {
        "id": "9yC3rAiucmWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP4a_I5ZcsuU",
        "outputId": "5feba2ee-3933-4897-92fc-5837a94a1a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'The': 0,\n",
              " 'dog': 1,\n",
              " 'ate': 2,\n",
              " 'the': 3,\n",
              " 'apple': 4,\n",
              " 'Everybody': 5,\n",
              " 'read': 6,\n",
              " 'that': 7,\n",
              " 'book': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "emv1VCSsdcBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "    super(LSTMTagger, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "    self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    embedings = self.word_embeddings(sentence)\n",
        "    lstm_out, _ = self.lstm(embedings.view(len(sentence), 1, -1))\n",
        "    tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "    tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "    return tag_scores"
      ],
      "metadata": {
        "id": "aBWpF2PkdLtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model before training"
      ],
      "metadata": {
        "id": "Puho8htXgjNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "model.to(device)\n",
        "loss_func = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
        "\n",
        "with torch.no_grad():\n",
        "  inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "  tag_scores = model(inputs)\n",
        "  print(tag_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV3oc5AdfTKW",
        "outputId": "b0bf8a28-f952-45ce-dc17-60e3c99a5add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.1110, -1.3284, -0.9018],\n",
            "        [-1.0342, -1.3603, -0.9470],\n",
            "        [-1.0272, -1.2792, -1.0113],\n",
            "        [-1.0824, -1.1896, -1.0304],\n",
            "        [-0.9993, -1.3510, -0.9865]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training model"
      ],
      "metadata": {
        "id": "Fxsxd-dbjIQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(300):\n",
        "  for sentence, tags in training_data:\n",
        "    model.zero_grad()\n",
        "    sentence_input = prepare_sequence(sentence, word_to_ix)\n",
        "    targets = prepare_sequence(tags, tag_to_ix)\n",
        "\n",
        "    tag_scores = model(sentence_input)\n",
        "\n",
        "    loss = loss_func(tag_scores, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# See what the scores are after training\n",
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    tag_scores = model(inputs)\n",
        "\n",
        "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
        "    # for word i. The predicted tag is the maximum scoring tag.\n",
        "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
        "    # since 0 is index of the maximum value of row 1,\n",
        "    # 1 is the index of maximum value of row 2, etc.\n",
        "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
        "    print(tag_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCH5IObJgYtF",
        "outputId": "fdc50a3c-76a9-4e39-988a-5ed15557ac9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0863, -0.5567, -2.4143],\n",
            "        [-1.3844, -0.5839, -1.6513],\n",
            "        [-1.6265, -1.9055, -0.4237],\n",
            "        [-0.3350, -1.7497, -2.1998],\n",
            "        [-1.9936, -0.2018, -3.0682]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use word embedding \n",
        "\n",
        "1. We need to define an index for each word when using embeddings.\n",
        "2. Embeddings are stored as a $|V| \\times D$ maxtrix, where D is the dimensionality of the embeddings. \n",
        "3. We can use torch.nn.Embedding(vocab_size, embedding_dim) to create word embedding"
      ],
      "metadata": {
        "id": "duFl4-wgktqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
        "embeds = nn.Embedding(2, 5)\n",
        "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
        "hello_embed = embeds(lookup_tensor)\n",
        "print(hello_embed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEHVmmrnjxr_",
        "outputId": "d5870e18-81e0-4f91-ea37-b5c53f5f3fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6502, -0.1108,  0.3221,  2.5179, -2.1227]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examples"
      ],
      "metadata": {
        "id": "RChsyJ8lloL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 10\n",
        "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
        "And dig deep trenches in thy beauty's field,\n",
        "Thy youth's proud livery so gazed on now,\n",
        "Will be a totter'd weed of small worth held:\n",
        "Then being asked, where all thy beauty lies,\n",
        "Where all the treasure of thy lusty days;\n",
        "To say, within thine own deep sunken eyes,\n",
        "Were an all-eating shame, and thriftless praise.\n",
        "How much more praise deserv'd thy beauty's use,\n",
        "If thou couldst answer 'This fair child of mine\n",
        "Shall sum my count, and make my old excuse,'\n",
        "Proving his beauty by succession thine!\n",
        "This were to be new made when thou art old,\n",
        "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
      ],
      "metadata": {
        "id": "ZLcL_n1wli9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams = [\n",
        "    (\n",
        "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
        "        test_sentence[i]\n",
        "    )\n",
        "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
        "]\n",
        "ngrams[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRy-Ad_TltqJ",
        "outputId": "52f5dc56-cab7-42f6-99e2-724ecc262d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['forty', 'When'], 'winters')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
        "\n",
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "data = []\n",
        "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
        "    context = (\n",
        "        [raw_text[i - j - 1] for j in range(CONTEXT_SIZE)]\n",
        "        + [raw_text[i + j + 1] for j in range(CONTEXT_SIZE)]\n",
        "    )\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "print(data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCtRS7EYlxgt",
        "outputId": "7b33ca31-b5eb-4d76-932e-647eecbe0529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['are', 'We', 'to', 'study'], 'about'), (['about', 'are', 'study', 'the'], 'to'), (['to', 'about', 'the', 'idea'], 'study'), (['study', 'to', 'idea', 'of'], 'the'), (['the', 'study', 'of', 'a'], 'idea')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.context_size = context_size\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs)\n",
        "        inputs = torch.sum(embeds, dim=0).view(1, -1)\n",
        "        output = self.linear1(inputs)\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "jAGTA0ROm-Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "model = CBOW(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE * 2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "4cL2X549qd0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  total_loss = 0\n",
        "  for context, target in data:\n",
        "    context_idxs = torch.tensor([word_to_ix[word] for word in context], dtype=torch.long)\n",
        "    optimizer.zero_grad()\n",
        "    log_prob = model(context_idxs)\n",
        "    loss = loss_function(log_prob, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  losses.append(total_loss)\n"
      ],
      "metadata": {
        "id": "WRauRbhIq_su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings.weight[word_to_ix[\"Computational\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1W2pomitGKN",
        "outputId": "1f9e0e5a-8913-4f41-8d14-e2278ec69815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.6469, -1.1509, -0.5670, -0.9811,  0.3269, -2.0446,  0.6276, -0.5581,\n",
              "         0.1497,  1.0674], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNJFwKGDrP5s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}